{"cells":[{"cell_type":"code","source":["from pyspark.sql import Row\n","from datetime import datetime\n","\n","# Initial Data (e.g., simplified patient data)\n","data = [\n","    Row(id=1, name='Alice Smith', value=100.0, updated_timestamp=datetime(2024, 10, 26, 10, 0, 0)),\n","    Row(id=2, name='Bob Johnson', value=200.0, updated_timestamp=datetime(2024, 10, 26, 10, 5, 0)),\n","    Row(id=3, name='Charlie Brown', value=300.0, updated_timestamp=datetime(2024, 10, 26, 10, 10, 0))\n","]\n","initial_df = spark.createDataFrame(data)\n","\n","# Define the managed table name in the Lakehouse\n","source_table_name = \"HealthcareData.source_patient_data_managed\"\n","\n","# Write initial data to a managed Delta table\n","# Using mode(\"overwrite\") for a clean start each demo run\n","initial_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(source_table_name)\n","\n","print(f\"Initial managed source table '{source_table_name}' created.\")\n","\n","# Show the table exists and data is there via SQL\n","spark.sql(f\"SELECT * FROM {source_table_name}\").show()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":7,"statement_ids":[7],"state":"finished","livy_statement_state":"available","session_id":"3fee9106-5a6d-4f09-8952-bdbb91ed22a5","normalized_state":"finished","queued_time":"2025-04-25T20:49:34.9298725Z","session_start_time":null,"execution_start_time":"2025-04-25T20:49:34.9309432Z","execution_finish_time":"2025-04-25T20:50:05.9599574Z","parent_msg_id":"d085e1e9-9399-4999-b584-c81ee61f4daf"},"text/plain":"StatementMeta(, 3fee9106-5a6d-4f09-8952-bdbb91ed22a5, 7, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Initial managed source table 'HealthcareData.source_patient_data_managed' created.\n+---+-------------+-----+-------------------+\n| id|         name|value|  updated_timestamp|\n+---+-------------+-----+-------------------+\n|  1|  Alice Smith|100.0|2024-10-26 10:00:00|\n|  2|  Bob Johnson|200.0|2024-10-26 10:05:00|\n|  3|Charlie Brown|300.0|2024-10-26 10:10:00|\n+---+-------------+-----+-------------------+\n\n"]}],"execution_count":5,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"72106a88-904c-469a-a117-3c94fa1297e8"},{"cell_type":"code","source":["# Enable CDF for the managed table\n","spark.sql(f\"ALTER TABLE {source_table_name} SET TBLPROPERTIES (delta.enableChangeDataFeed = true)\")\n","\n","print(f\"CDF enabled for managed table '{source_table_name}'.\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":8,"statement_ids":[8],"state":"finished","livy_statement_state":"available","session_id":"3fee9106-5a6d-4f09-8952-bdbb91ed22a5","normalized_state":"finished","queued_time":"2025-04-25T20:50:17.3090236Z","session_start_time":null,"execution_start_time":"2025-04-25T20:50:17.3101672Z","execution_finish_time":"2025-04-25T20:50:18.7679677Z","parent_msg_id":"fb477789-efa3-42d6-a5f5-c4a0b9f86e8e"},"text/plain":"StatementMeta(, 3fee9106-5a6d-4f09-8952-bdbb91ed22a5, 8, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["CDF enabled for managed table 'HealthcareData.source_patient_data_managed'.\n"]}],"execution_count":6,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"256f3726-bc2c-494e-b642-6b6095444dc3"},{"cell_type":"code","source":["spark.sql(f\"SHOW TBLPROPERTIES {source_table_name}\").show()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":9,"statement_ids":[9],"state":"finished","livy_statement_state":"available","session_id":"3fee9106-5a6d-4f09-8952-bdbb91ed22a5","normalized_state":"finished","queued_time":"2025-04-25T20:50:34.6279494Z","session_start_time":null,"execution_start_time":"2025-04-25T20:50:34.629173Z","execution_finish_time":"2025-04-25T20:50:35.4454208Z","parent_msg_id":"4a1e8d48-8ef9-4c5a-9395-8693dd66e4c8"},"text/plain":"StatementMeta(, 3fee9106-5a6d-4f09-8952-bdbb91ed22a5, 9, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["+--------------------+-----+\n|                 key|value|\n+--------------------+-----+\n|delta.enableChang...| true|\n|delta.minReaderVe...|    1|\n|delta.minWriterVe...|    4|\n|delta.parquet.vor...| true|\n+--------------------+-----+\n\n"]}],"execution_count":7,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"5a568f83-87ae-4448-964c-43afcc0edd4b"},{"cell_type":"code","source":["# Insert new data (e.g., new patient) using SQL INSERT\n","spark.sql(f\"\"\"\n","  INSERT INTO {source_table_name} VALUES\n","  (4, 'David Green', 400.0, '{datetime(2024, 10, 27, 11, 0, 0)}')\n","\"\"\")\n","\n","print(\"Inserted new record into managed table.\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":10,"statement_ids":[10],"state":"finished","livy_statement_state":"available","session_id":"3fee9106-5a6d-4f09-8952-bdbb91ed22a5","normalized_state":"finished","queued_time":"2025-04-25T20:50:46.5104619Z","session_start_time":null,"execution_start_time":"2025-04-25T20:50:46.5115162Z","execution_finish_time":"2025-04-25T20:50:47.9932681Z","parent_msg_id":"3c6531b2-fda9-48b4-958f-02761f0fcbf1"},"text/plain":"StatementMeta(, 3fee9106-5a6d-4f09-8952-bdbb91ed22a5, 10, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Inserted new record into managed table.\n"]}],"execution_count":8,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"5085f685-0d2b-477a-86d4-dcde61975f99"},{"cell_type":"code","source":["# Update existing data (e.g., id=1, patient Alice's value changed) using SQL UPDATE\n","spark.sql(f\"\"\"\n","  UPDATE {source_table_name}\n","  SET value = 150.0, updated_timestamp = '{datetime(2024, 10, 27, 11, 10, 0)}'\n","  WHERE id = 1\n","\"\"\")\n","\n","print(\"Updated a record in managed table.\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":11,"statement_ids":[11],"state":"finished","livy_statement_state":"available","session_id":"3fee9106-5a6d-4f09-8952-bdbb91ed22a5","normalized_state":"finished","queued_time":"2025-04-25T20:50:58.6138371Z","session_start_time":null,"execution_start_time":"2025-04-25T20:50:58.6150072Z","execution_finish_time":"2025-04-25T20:51:03.3456033Z","parent_msg_id":"47c8f608-c6a6-48d3-a8ca-e9161558f491"},"text/plain":"StatementMeta(, 3fee9106-5a6d-4f09-8952-bdbb91ed22a5, 11, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Updated a record in managed table.\n"]}],"execution_count":9,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"0c7ac239-d7b9-4bb5-8d20-bcacea660db9"},{"cell_type":"code","source":["# Delete data (e.g., id=3, patient Charlie discharged/record removed) using SQL DELETE\n","spark.sql(f\"\"\"\n","  DELETE FROM {source_table_name}\n","  WHERE id = 3\n","\"\"\")\n","\n","print(\"Deleted a record from managed table.\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":12,"statement_ids":[12],"state":"finished","livy_statement_state":"available","session_id":"3fee9106-5a6d-4f09-8952-bdbb91ed22a5","normalized_state":"finished","queued_time":"2025-04-25T20:51:07.932742Z","session_start_time":null,"execution_start_time":"2025-04-25T20:51:07.9339758Z","execution_finish_time":"2025-04-25T20:51:12.5555914Z","parent_msg_id":"77ea4493-eca9-4b45-9523-50e516de07ee"},"text/plain":"StatementMeta(, 3fee9106-5a6d-4f09-8952-bdbb91ed22a5, 12, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Deleted a record from managed table.\n"]}],"execution_count":10,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"64de3211-29db-48a9-b669-6081aba5ea2e"},{"cell_type":"code","source":["spark.sql(f\"DESCRIBE HISTORY {source_table_name}\").show()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":13,"statement_ids":[13],"state":"finished","livy_statement_state":"available","session_id":"3fee9106-5a6d-4f09-8952-bdbb91ed22a5","normalized_state":"finished","queued_time":"2025-04-25T20:51:19.7875825Z","session_start_time":null,"execution_start_time":"2025-04-25T20:51:19.7887861Z","execution_finish_time":"2025-04-25T20:51:21.2348532Z","parent_msg_id":"eb6b7dbc-e0bf-40cb-9833-6d4f5d176fd6"},"text/plain":"StatementMeta(, 3fee9106-5a6d-4f09-8952-bdbb91ed22a5, 13, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["+-------+--------------------+------+--------+--------------------+--------------------+----+--------+---------+-----------+--------------+-------------+--------------------+------------+--------------------+\n|version|           timestamp|userId|userName|           operation| operationParameters| job|notebook|clusterId|readVersion|isolationLevel|isBlindAppend|    operationMetrics|userMetadata|          engineInfo|\n+-------+--------------------+------+--------+--------------------+--------------------+----+--------+---------+-----------+--------------+-------------+--------------------+------------+--------------------+\n|      4|2025-04-25 20:51:...|  NULL|    NULL|              DELETE|{predicate -> [\"(...|NULL|    NULL|     NULL|          3|  Serializable|        false|{numRemovedFiles ...|        NULL|Apache-Spark/3.5....|\n|      3|2025-04-25 20:51:...|  NULL|    NULL|              UPDATE|{predicate -> [\"(...|NULL|    NULL|     NULL|          2|  Serializable|        false|{numRemovedFiles ...|        NULL|Apache-Spark/3.5....|\n|      2|2025-04-25 20:50:...|  NULL|    NULL|               WRITE|{mode -> Append, ...|NULL|    NULL|     NULL|          1|  Serializable|         true|{numFiles -> 1, n...|        NULL|Apache-Spark/3.5....|\n|      1|2025-04-25 20:50:...|  NULL|    NULL|   SET TBLPROPERTIES|{properties -> {\"...|NULL|    NULL|     NULL|          0|  Serializable|         true|                  {}|        NULL|Apache-Spark/3.5....|\n|      0|2025-04-25 20:49:...|  NULL|    NULL|CREATE OR REPLACE...|{partitionBy -> [...|NULL|    NULL|     NULL|       NULL|  Serializable|        false|{numFiles -> 1, n...|        NULL|Apache-Spark/3.5....|\n+-------+--------------------+------+--------+--------------------+--------------------+----+--------+---------+-----------+--------------+-------------+--------------------+------------+--------------------+\n\n"]}],"execution_count":11,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"bbf90a65-9f57-478c-b48c-47f4fd9e7b90"},{"cell_type":"code","source":["# Define the version to start reading from (ADJUST based on your DESCRIBE HISTORY output)\n","starting_version = 1 # Example: If version 0 was initial write, changes start from 1.\n","\n","# Define the ABFSS path for the managed table's data location in OneLake\n","workspace_name = \"Healthcare\" # Your workspace name\n","lakehouse_name = \"HealthcareData\" # Your Lakehouse name\n","managed_table_simple_name = source_table_name.split('.')[-1] # Get just the table name part\n","abfss_path_to_table = f\"abfss://{workspace_name}@onelake.dfs.fabric.microsoft.com/{lakehouse_name}.Lakehouse/Tables/{managed_table_simple_name}\"\n","\n","# Read the change data feed using the ABFSS path and CDF options\n","change_df = spark.read.format(\"delta\") \\\n","    .option(\"readChangeFeed\", \"true\") \\\n","    .option(\"startingVersion\", starting_version) \\\n","    .load(abfss_path_to_table)\n","\n","print(f\"Read change data from version {starting_version} from ABFSS path {abfss_path_to_table}.\")\n","change_df.show(truncate=False)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":29,"statement_ids":[29],"state":"finished","livy_statement_state":"available","session_id":"3fee9106-5a6d-4f09-8952-bdbb91ed22a5","normalized_state":"finished","queued_time":"2025-04-25T21:26:14.893557Z","session_start_time":null,"execution_start_time":"2025-04-25T21:26:14.894752Z","execution_finish_time":"2025-04-25T21:26:17.2650936Z","parent_msg_id":"41c60294-72c0-4a3f-b339-fac57ee8828e"},"text/plain":"StatementMeta(, 3fee9106-5a6d-4f09-8952-bdbb91ed22a5, 29, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Read change data from version 1 from ABFSS path abfss://Healthcare@onelake.dfs.fabric.microsoft.com/HealthcareData.Lakehouse/Tables/source_patient_data_managed.\n+---+-------------+-----+-------------------+----------------+---------------+-----------------------+\n|id |name         |value|updated_timestamp  |_change_type    |_commit_version|_commit_timestamp      |\n+---+-------------+-----+-------------------+----------------+---------------+-----------------------+\n|1  |Alice Smith  |100.0|2024-10-26 10:00:00|update_preimage |3              |2025-04-25 20:51:02.595|\n|1  |Alice Smith  |150.0|2024-10-27 11:10:00|update_postimage|3              |2025-04-25 20:51:02.595|\n|3  |Charlie Brown|300.0|2024-10-26 10:10:00|delete          |4              |2025-04-25 20:51:10.94 |\n|4  |David Green  |400.0|2024-10-27 11:00:00|insert          |2              |2025-04-25 20:50:47.359|\n+---+-------------+-----+-------------------+----------------+---------------+-----------------------+\n"]}],"execution_count":26,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"0142450d-b7bd-4c77-992b-441057e360b6"},{"cell_type":"code","source":["# Define target managed table name\n","target_table_name = \"HealthcareData.target_patient_data_managed\"\n","\n","# --- FIX: Correctly Initialize Target Table with Initial Data (Simulate Initial Load) ---\n","# Instead of dropping and creating an empty table, we will populate it\n","# with the data from the source table at version 0 (the initial write).\n","# This simulates the \"first run\" or initial load of the target table.\n","\n","initial_source_data_at_v0 = spark.read.format(\"delta\") \\\n","    .option(\"versionAsOf\", 0) \\\n","    .load(abfss_path_to_table) # Use the ABFSS path\n","\n","# Overwrite the target table with this initial data\n","initial_source_data_at_v0.write.format(\"delta\").mode(\"overwrite\").saveAsTable(target_table_name)\n","\n","print(f\"Target managed table '{target_table_name}' initialized with data from source version 0 (simulating initial load).\")\n","\n","# --- Show the state after initial load (optional) ---\n","print(f\"State of target table after initial load (version 0 from source):\")\n","spark.read.table(target_table_name).show()\n","\n","\n","# --- Continue with processing changes from CDF (Incremental Load Logic) ---\n","\n","# Process changes: Filter out update_preimage and select relevant columns explicitly\n","changes_for_merge = change_df.filter(\"_change_type != 'update_preimage'\") \\\n","                             .select(\"id\", \"name\", \"value\", \"updated_timestamp\", \"_change_type\") # Select necessary columns\n","\n","# Register the filtered changes as a temporary view\n","temp_view_name = \"temp_cdc_changes_for_merge\"\n","changes_for_merge.createOrReplaceTempView(temp_view_name)\n","\n","print(f\"Filtered changes registered as temporary view '{temp_view_name}'.\")\n","\n","# Perform the MERGE operation on the target managed table (which is now NOT empty)\n","# using the TEMPORARY VIEW. This MERGE logic is correct for incremental updates.\n","spark.sql(f\"\"\"\n","  MERGE INTO {target_table_name} AS target\n","  USING {temp_view_name} AS source  -- Use the temporary view as the source\n","  ON target.id = source.id\n","  WHEN MATCHED AND source._change_type = 'update_postimage' THEN\n","    UPDATE SET\n","      target.name = source.name,\n","      target.value = source.value,\n","      target.updated_timestamp = source.updated_timestamp\n","  WHEN MATCHED AND source._change_type = 'delete' THEN\n","    DELETE\n","  WHEN NOT MATCHED AND source._change_type = 'insert' THEN\n","    INSERT (id, name, value, updated_timestamp)\n","    VALUES (source.id, source.name, source.value, source.updated_timestamp)\n","\"\"\")\n","\n","print(f\"Incremental changes applied to the target managed table '{target_table_name}' using temporary view '{temp_view_name}'.\")\n","\n","# --- Optional: Clean up the temporary view when done ---\n","# spark.catalog.dropTempView(temp_view_name)\n","# print(f\"Temporary view '{temp_view_name}' dropped.\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":30,"statement_ids":[30],"state":"finished","livy_statement_state":"available","session_id":"3fee9106-5a6d-4f09-8952-bdbb91ed22a5","normalized_state":"finished","queued_time":"2025-04-25T21:26:41.0529647Z","session_start_time":null,"execution_start_time":"2025-04-25T21:26:41.0541745Z","execution_finish_time":"2025-04-25T21:26:50.7452105Z","parent_msg_id":"b827e573-7b70-4e5e-b4ba-c88736f0a2fc"},"text/plain":"StatementMeta(, 3fee9106-5a6d-4f09-8952-bdbb91ed22a5, 30, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Target managed table 'HealthcareData.target_patient_data_managed' initialized with data from source version 0 (simulating initial load).\nState of target table after initial load (version 0 from source):\n+---+-------------+-----+-------------------+\n| id|         name|value|  updated_timestamp|\n+---+-------------+-----+-------------------+\n|  1|  Alice Smith|100.0|2024-10-26 10:00:00|\n|  2|  Bob Johnson|200.0|2024-10-26 10:05:00|\n|  3|Charlie Brown|300.0|2024-10-26 10:10:00|\n+---+-------------+-----+-------------------+\n\nFiltered changes registered as temporary view 'temp_cdc_changes_for_merge'.\nIncremental changes applied to the target managed table 'HealthcareData.target_patient_data_managed' using temporary view 'temp_cdc_changes_for_merge'.\n"]}],"execution_count":27,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"cfc82949-462d-4261-ace4-20f7c37c7c54"},{"cell_type":"code","source":["from delta.tables import DeltaTable\n","from datetime import datetime\n","\n","# Get the latest commit version processed in this run from the original change_df\n","# We use the original change_df as it contains all change types and versions read\n","if change_df.count() > 0:\n","    latest_processed_version = change_df.agg({\"_commit_version\": \"max\"}).collect()[0][0]\n","    print(f\"Latest commit version processed in this run: {latest_processed_version}\")\n","\n","    # --- Store this version persistently in a control table (using DataFrame ops) ---\n","    # Define the name for your control table\n","    control_table_name = \"HealthcareData.cdf_control_versions\"\n","\n","    # Data for the new/updated watermark\n","    new_watermark_data = [(source_table_name, latest_processed_version, datetime.now())]\n","    new_watermark_df = spark.createDataFrame(new_watermark_data, [\"table_name\", \"last_processed_version\", \"processed_timestamp\"])\n","\n","    # Create the control table if it doesn't exist\n","    # This table will store the last processed version for each source table\n","    spark.sql(f\"\"\"\n","        CREATE TABLE IF NOT EXISTS {control_table_name}\n","        (table_name STRING, last_processed_version LONG, processed_timestamp TIMESTAMP)\n","        USING DELTA\n","    \"\"\")\n","    print(f\"Control table '{control_table_name}' ensured to exist.\")\n","\n","    # --- Read, Update/Add Row, and Overwrite the Control Table ---\n","    try:\n","        # Read the current state of the control table\n","        control_delta_table = DeltaTable.forName(spark, control_table_name)\n","        current_control_df = control_delta_table.toDF()\n","\n","        # Filter out the old row for the source table if it exists\n","        filtered_control_df = current_control_df.filter(f\"table_name != '{source_table_name}'\")\n","\n","        # Union the filtered data with the new watermark row\n","        updated_control_df = filtered_control_df.union(new_watermark_df)\n","\n","        # Overwrite the control table with the updated DataFrame\n","        updated_control_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(control_table_name)\n","\n","        print(f\"Watermark updated for '{source_table_name}' in control table '{control_table_name}' using overwrite.\")\n","\n","    except Exception as e:\n","         # This catch is mostly for initial table creation or unexpected issues\n","         # If the table didn't exist initially, the CREATE TABLE IF NOT EXISTS handles it.\n","         # For a robust production pipeline, more specific error handling might be needed.\n","         print(f\"Could not update control table using overwrite method: {e}\")\n","         # As a fallback for the very first run if the table was just created:\n","         try:\n","             new_watermark_df.write.format(\"delta\").mode(\"append\").saveAsTable(control_table_name)\n","             print(f\"Watermark appended for '{source_table_name}' (fallback append).\")\n","         except Exception as append_e:\n","             print(f\"Fallback append also failed: {append_e}\")\n","\n","\n","    # --- Read and show the state of the control table ---\n","    print(f\"Current state of the control table '{control_table_name}':\")\n","    spark.read.table(control_table_name).show(truncate=False) # Show all columns\n","\n","else:\n","    print(\"No changes were read from the change feed in this run. Watermark remains unchanged.\")\n","\n","# --- Optional: Clean up the temporary view ---\n","try:\n","     spark.catalog.dropTempView(\"temp_cdc_changes_for_merge\")\n","     print(\"Temporary view 'temp_cdc_changes_for_merge' dropped.\")\n","except Exception as e:\n","     # Ignore if view doesn't exist, just ensure cleanup attempt\n","     pass # print(f\"Temporary view 'temp_cdc_changes_for_merge' might not exist or failed to drop: {e}\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":31,"statement_ids":[31],"state":"finished","livy_statement_state":"available","session_id":"3fee9106-5a6d-4f09-8952-bdbb91ed22a5","normalized_state":"finished","queued_time":"2025-04-25T21:27:21.9631869Z","session_start_time":null,"execution_start_time":"2025-04-25T21:27:21.9644991Z","execution_finish_time":"2025-04-25T21:27:31.6504863Z","parent_msg_id":"d7846239-5d95-49db-8824-7692cffd2fb4"},"text/plain":"StatementMeta(, 3fee9106-5a6d-4f09-8952-bdbb91ed22a5, 31, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Latest commit version processed in this run: 4\nControl table 'HealthcareData.cdf_control_versions' ensured to exist.\nWatermark updated for 'HealthcareData.source_patient_data_managed' in control table 'HealthcareData.cdf_control_versions' using overwrite.\nCurrent state of the control table 'HealthcareData.cdf_control_versions':\n+------------------------------------------+----------------------+--------------------------+\n|table_name                                |last_processed_version|processed_timestamp       |\n+------------------------------------------+----------------------+--------------------------+\n|HealthcareData.source_patient_data_managed|4                     |2025-04-25 21:27:23.471805|\n+------------------------------------------+----------------------+--------------------------+\n\nTemporary view 'temp_cdc_changes_for_merge' dropped.\n"]}],"execution_count":28,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"b9b63fad-a5fe-49d6-861d-c10c59bf5ba2"},{"cell_type":"code","source":["# Define target managed table name\n","target_table_name = \"HealthcareData.target_patient_data_managed\"\n","\n","print(f\"\\n--- Final state of target managed table '{target_table_name}': ---\")\n","# Read the target table and display the contents\n","# Use .show() for a simple text output, or .display() in a notebook for a richer view\n","spark.read.table(target_table_name).show()\n","# Alternatively, using display():\n","# spark.read.table(target_table_name).display()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":32,"statement_ids":[32],"state":"finished","livy_statement_state":"available","session_id":"3fee9106-5a6d-4f09-8952-bdbb91ed22a5","normalized_state":"finished","queued_time":"2025-04-25T21:27:35.610615Z","session_start_time":null,"execution_start_time":"2025-04-25T21:27:35.6118496Z","execution_finish_time":"2025-04-25T21:27:37.9612302Z","parent_msg_id":"d3509070-d17c-4cc7-96e7-5ed60e93eda7"},"text/plain":"StatementMeta(, 3fee9106-5a6d-4f09-8952-bdbb91ed22a5, 32, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["--- Final state of target managed table 'HealthcareData.target_patient_data_managed': ---\n+---+-----------+-----+-------------------+\n| id|       name|value|  updated_timestamp|\n+---+-----------+-----+-------------------+\n|  1|Alice Smith|150.0|2024-10-27 11:10:00|\n|  4|David Green|400.0|2024-10-27 11:00:00|\n|  2|Bob Johnson|200.0|2024-10-26 10:05:00|\n+---+-----------+-----+-------------------+\n"]}],"execution_count":29,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"4310794b-22d9-4350-9ea6-ee41312a8caf"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"synapse_widget":{"version":"0.1","state":{}},"dependencies":{"lakehouse":{"known_lakehouses":[{"id":"1d3b6cad-9230-4783-9df1-f821711b1c8f"}],"default_lakehouse":"1d3b6cad-9230-4783-9df1-f821711b1c8f","default_lakehouse_name":"HealthcareData","default_lakehouse_workspace_id":"8ecba42e-a6c5-4672-854f-d570b4f45d10"}}},"nbformat":4,"nbformat_minor":5}